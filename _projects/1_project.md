---
layout: page
title: Open Data for Language Models
# description: I curate and release large-scale, high-quality datasets and corpora to support open and accessible AI research.

# img: assets/img/12.jpg
importance: 1
category: work
---

<!-- I curate and release large-scale, high-quality datasets and corpora to support open science in AI research. -->

I am co-leading Data Research for [OLMo](https://allenai.org/olmo). We've released:
* [Dolma](https://huggingface.co/datasets/allenai/dolma), the largest open dataset for language model pretraining to-date. Dolma won a best paper award at ACL 2024 üèÜ!
* [peS2o](https://huggingface.co/datasets/allenai/peS2o), a transformation of S2ORC optimized for pretraining language models of science. Dolma won a best paper award at ACL 2024 üèÜ!

Prior to this, I co-led the curation of:
* [S2ORC](https://aclanthology.org/2020.acl-main.447), the largest, machine-readable collection of open-access full-text papers to-date. Request API access üîë [here](https://www.semanticscholar.org/product/api)!
* [CORD-19](https://aclanthology.org/2020.nlpcovid19-acl.1/), the most comprehensive, continually-updated set of COVID-19 literature at the time, and


<!-- In 2024, I'll be working on large-scale, multimodal datasets! -->