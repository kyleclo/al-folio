---
layout: post
date: 2024-02-01 00:00:01-0800
inline: true
---

Excited to release our first set of artifacts from the OLMo project ðŸ¥³

**Want models?**
Download our open-source weights at [1B](https://huggingface.co/allenai/OLMo-1B) and a pair of weights at [7B](https://huggingface.co/allenai/OLMo-7B) and [7B](https://huggingface.co/allenai/OLMo-7B-Twin-2T) scale, trained on different hardware, on Huggingface. We also open-source all our [training and inference code](https://github.com/allenai/OLMo). Learn more from our [paper](https://allenai.org/olmo/olmo-paper.pdf).

**Want data?**
Download all 3T tokens on [Huggingface](https://huggingface.co/datasets/allenai/dolma). We also open-source all our [dataset construction tools](https://github.com/allenai/dolma). Learn more from our [paper](https://allenai.org/olmo/dolma-paper.pdf).
